<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ninad AI - Robust Edition</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Mukta:wght@300;400;600;800&display=swap');
        body { font-family: 'Mukta', sans-serif; }

        /* Animations */
        .pulse-ring {
            animation: pulse-ring 2s infinite;
        }
        @keyframes pulse-ring {
            0% { box-shadow: 0 0 0 0 rgba(59, 130, 246, 0.7); }
            70% { box-shadow: 0 0 0 15px rgba(59, 130, 246, 0); }
            100% { box-shadow: 0 0 0 0 rgba(59, 130, 246, 0); }
        }
        .speaking-ring {
            animation: speaking-ring 1.5s infinite;
        }
        @keyframes speaking-ring {
            0% { box-shadow: 0 0 0 0 rgba(16, 185, 129, 0.7); }
            70% { box-shadow: 0 0 0 15px rgba(16, 185, 129, 0); }
            100% { box-shadow: 0 0 0 0 rgba(16, 185, 129, 0); }
        }
    </style>
</head>
<body class="bg-gray-900 text-white h-screen flex flex-col">

    <div id="setup-overlay" class="fixed inset-0 bg-gray-900 z-50 flex flex-col items-center justify-center p-6 transition-opacity duration-500">
        <h1 class="text-4xl font-extrabold text-blue-500 mb-2">Project Ninad</h1>
        <p class="text-gray-400 mb-6">Male Marathi Teacher (Robust Audio)</p>
        
        <div class="w-full max-w-md space-y-4">
            <label class="text-xs text-gray-500 uppercase font-bold tracking-wider">OpenAI API Key (Required for Male Voice)</label>
            <input type="password" id="api-input" placeholder="sk-..." 
                   class="w-full p-4 bg-gray-800 border border-gray-700 rounded-lg text-white focus:border-blue-500 outline-none">
            
            <button id="start-btn" class="w-full bg-blue-600 hover:bg-blue-500 text-white font-bold py-4 rounded-lg shadow-lg transform active:scale-95 transition-all">
                Start System
            </button>
            <p class="text-xs text-gray-600 text-center">
                If the API key is wrong, I will fallback to a robotic browser voice automatically.
            </p>
        </div>
    </div>

    <div class="flex-1 flex flex-col max-w-3xl mx-auto w-full p-4">
        
        <div class="flex justify-between items-center border-b border-gray-800 pb-4">
            <div class="flex items-center gap-3">
                <div class="w-12 h-12 rounded-full bg-gradient-to-br from-blue-500 to-blue-700 flex items-center justify-center text-xl font-bold shadow-lg">
                    N
                </div>
                <div>
                    <h2 class="text-xl font-bold">Ninad Sir</h2>
                    <div class="flex items-center gap-2">
                        <span id="status-dot" class="w-2 h-2 rounded-full bg-gray-500"></span>
                        <span id="status-text" class="text-xs text-gray-400">Offline</span>
                    </div>
                </div>
            </div>
            <div class="text-right">
                <p id="user-info" class="text-sm text-gray-400">Guest</p>
            </div>
        </div>

        <div id="chat-box" class="flex-1 overflow-y-auto py-4 space-y-6 scroll-smooth">
            <div class="text-center text-gray-600 mt-10 text-sm">
                System Ready.<br>Say <strong>"Ninad"</strong> clearly.
            </div>
        </div>

        <div id="debug-log" class="text-xs text-red-400 font-mono h-6 overflow-hidden text-center opacity-0 transition-opacity"></div>

        <div class="py-6 flex justify-center relative">
            <div id="visualizer" class="w-24 h-24 rounded-full bg-gray-800 border-4 border-gray-700 flex items-center justify-center transition-all duration-300">
                <svg id="mic-icon" xmlns="http://www.w3.org/2000/svg" class="h-10 w-10 text-gray-400" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z" />
                </svg>
            </div>
        </div>
    </div>

    <script>
        // --- Variables ---
        let apiKey = "";
        let recognition;
        let audioContext; // For unlocking audio
        
        // State: IDLE, LISTENING, PROCESSING, SPEAKING
        let state = "IDLE";
        
        let userData = { name: "", age: 0, effectiveAge: 18 };
        let conversationHistory = [];

        // --- Elements ---
        const startBtn = document.getElementById('start-btn');
        const setupOverlay = document.getElementById('setup-overlay');
        const statusText = document.getElementById('status-text');
        const statusDot = document.getElementById('status-dot');
        const visualizer = document.getElementById('visualizer');
        const micIcon = document.getElementById('mic-icon');
        const chatBox = document.getElementById('chat-box');
        const debugLog = document.getElementById('debug-log');
        const userInfo = document.getElementById('user-info');

        // --- Initialization ---
        startBtn.addEventListener('click', async () => {
            apiKey = document.getElementById('api-input').value.trim();
            
            // Unlock Audio Context (Crucial for browsers)
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            await audioContext.resume();

            // Setup Speech Recognition
            if (!('webkitSpeechRecognition' in window)) {
                alert("Please use Google Chrome.");
                return;
            }

            recognition = new webkitSpeechRecognition();
            recognition.lang = 'mr-IN'; // Marathi
            recognition.continuous = false;
            recognition.interimResults = false;

            recognition.onstart = () => updateState('LISTENING');
            recognition.onend = () => {
                if (state === 'LISTENING') recognition.start(); // Auto-restart
                else updateState('IDLE');
            };
            recognition.onresult = handleSpeechInput;

            // Hide Overlay
            setupOverlay.style.opacity = '0';
            setTimeout(() => setupOverlay.remove(), 500);

            // Start
            try {
                recognition.start();
            } catch(e) { console.error(e); }
            
            addBubble("System", "Namaskar. Say 'Ninad' to wake me up.");
        });

        // --- Core Logic ---

        async function handleSpeechInput(event) {
            const transcript = event.results[0][0].transcript.trim();
            const cleanText = transcript.toLowerCase();
            console.log("Heard:", transcript);

            // Wake Word Detection
            if (userData.name === "") {
                // Phase 1: Not Identified Yet
                if (cleanText.includes('ninad') || cleanText.includes('निनाद')) {
                    updateState('PROCESSING');
                    addBubble("You", transcript);
                    await speak("Namaskar! Mi Ninad. Tumche naav kay aahe?");
                    return;
                }
                
                // Phase 2: Name Input
                if (conversationHistory.length === 0 && !cleanText.includes('ninad')) {
                   // Check if we just asked for name
                   // Rudimentary state tracking via "Last Bot Message" logic isn't here, 
                   // so we use a simple flag approach based on empty userData
                   // But wait, we need to know if we *asked* for the name.
                   // Let's simplify: If user says something and name is empty, assume it's name ONLY IF we triggered previously.
                   // To make this robust, let's just check pattern.
                }
            }

            // Simple State Machine based on what we have
            if (state === 'IDLE' || state === 'LISTENING') {
                
                // 1. Wake Word
                if (cleanText.includes('ninad') || cleanText.includes('निनाद')) {
                    updateState('PROCESSING');
                    addBubble("You", transcript);
                    conversationHistory = []; // Reset on wake
                    userData = { name: "", age: 0, effectiveAge: 18 }; // Reset user
                    await speak("Namaskar! Mi Ninad. Tumche naav kay aahe?");
                    userData.step = "WAITING_FOR_NAME";
                } 
                // 2. Name Input
                else if (userData.step === "WAITING_FOR_NAME") {
                    updateState('PROCESSING');
                    addBubble("You", transcript);
                    
                    // Simple Name Extraction (Take last word or remove common phrases)
                    let name = transcript.replace(/majhe naav/i, '').replace(/aahe/i, '').replace(/mi/i, '').trim();
                    userData.name = name;
                    userData.step = "WAITING_FOR_AGE";
                    userInfo.innerText = name;
                    
                    await speak(`Khup chan ${name}. Tumche vay kay aahe?`);
                }
                // 3. Age Input
                else if (userData.step === "WAITING_FOR_AGE") {
                    updateState('PROCESSING');
                    addBubble("You", transcript);
                    
                    let age = transcript.match(/\d+/);
                    userData.age = age ? parseInt(age[0]) : 18;
                    userData.effectiveAge = userData.age > 18 ? 18 : userData.age;
                    userData.step = "TEACHER_MODE";
                    userInfo.innerText = `${userData.name} (${userData.age})`;

                    await speak("Mast! Chala abhyas karuya. Tumhala kay shikaycha aahe?");
                }
                // 4. Teacher Mode
                else if (userData.step === "TEACHER_MODE") {
                    updateState('PROCESSING');
                    addBubble("You", transcript);
                    await getAIResponse(transcript);
                }
            }
        }

        // --- OpenAI Intelligence ---
        async function getAIResponse(userText) {
            if (!apiKey.startsWith("sk-")) {
                // Dummy response if no key
                await speak("Mala tumche bolne samajle, pan API key chuki ahe.");
                return;
            }

            let messages = [
                { role: "system", content: `You are Ninad, a polite, soft-spoken Marathi male teacher. User: ${userData.name}, Age: ${userData.effectiveAge}. Language: Marathi. Keep answers short and simple. End with a question.` },
                ...conversationHistory,
                { role: "user", content: userText }
            ];

            try {
                const res = await fetch("https://api.openai.com/v1/chat/completions", {
                    method: "POST",
                    headers: { "Content-Type": "application/json", "Authorization": `Bearer ${apiKey}` },
                    body: JSON.stringify({ model: "gpt-4o-mini", messages: messages, max_tokens: 100 })
                });
                
                if(!res.ok) throw new Error("GPT Error");

                const data = await res.json();
                const reply = data.choices[0].message.content;
                
                conversationHistory.push({ role: "user", content: userText });
                conversationHistory.push({ role: "assistant", content: reply });
                
                await speak(reply);

            } catch(e) {
                logError("AI Brain Failed: " + e.message);
                await speak("Maaf kara, mala thoda vel lagat aahe.");
            }
        }

        // --- ROBUST TTS ENGINE (The Fix) ---
        async function speak(text) {
            addBubble("Ninad", text);
            updateState('SPEAKING');
            recognition.stop(); // Stop mic so it doesn't hear itself

            // 1. Attempt OpenAI TTS (High Quality)
            if (apiKey.startsWith("sk-")) {
                try {
                    const res = await fetch("https://api.openai.com/v1/audio/speech", {
                        method: "POST",
                        headers: { "Content-Type": "application/json", "Authorization": `Bearer ${apiKey}` },
                        body: JSON.stringify({
                            model: "tts-1",
                            input: text,
                            voice: "onyx", // The Male Voice
                            response_format: "mp3"
                        })
                    });

                    if (!res.ok) {
                        const errText = await res.text();
                        throw new Error(`OpenAI TTS Failed: ${res.status} - ${errText}`);
                    }

                    const blob = await res.blob();
                    const url = URL.createObjectURL(blob);
                    const audio = new Audio(url);

                    await new Promise((resolve) => {
                        audio.onended = resolve;
                        audio.onerror = () => { throw new Error("Audio Playback Error"); };
                        audio.play().catch(e => { throw new Error("Autoplay Blocked: " + e.message); });
                    });

                    // Success!
                    updateState('LISTENING');
                    try { recognition.start(); } catch(e){}
                    return; // Exit function

                } catch (e) {
                    logError(e.message);
                    // Do not stop here! Fall through to browser voice.
                }
            } else {
                logError("No valid API Key. Using Fallback Voice.");
            }

            // 2. Fallback: Browser TTS (Low Quality but Works)
            console.log("Falling back to Browser Voice");
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.lang = 'mr-IN';
            
            // Try to find a Google/Native Hindi/Marathi voice
            const voices = window.speechSynthesis.getVoices();
            // Try to find a male-sounding voice name if possible, or just Hindi (often better than generic)
            const bestVoice = voices.find(v => v.lang === 'mr-IN') || voices.find(v => v.lang === 'hi-IN');
            if (bestVoice) utterance.voice = bestVoice;
            
            // Pitch shift to simulate male if using default female voice
            utterance.pitch = 0.6; 
            utterance.rate = 0.9;

            utterance.onend = () => {
                updateState('LISTENING');
                try { recognition.start(); } catch(e){}
            };

            window.speechSynthesis.speak(utterance);
        }

        // --- Helper Functions ---

        function updateState(newState) {
            state = newState;
            statusText.innerText = newState;
            
            // Reset classes
            visualizer.className = "w-24 h-24 rounded-full flex items-center justify-center transition-all duration-300 border-4";
            micIcon.className = "h-10 w-10 transition-colors";

            if (newState === 'LISTENING') {
                statusDot.className = "w-2 h-2 rounded-full bg-green-500";
                visualizer.classList.add("bg-gray-800", "border-blue-500", "pulse-ring");
                micIcon.classList.add("text-blue-400");
            } else if (newState === 'SPEAKING') {
                statusDot.className = "w-2 h-2 rounded-full bg-blue-500";
                visualizer.classList.add("bg-blue-900", "border-green-500", "speaking-ring");
                micIcon.classList.add("text-green-400");
            } else if (newState === 'PROCESSING') {
                statusDot.className = "w-2 h-2 rounded-full bg-yellow-500";
                visualizer.classList.add("bg-gray-800", "border-yellow-500");
                micIcon.classList.add("text-yellow-400");
            } else {
                statusDot.className = "w-2 h-2 rounded-full bg-gray-500";
                visualizer.classList.add("bg-gray-800", "border-gray-700");
                micIcon.classList.add("text-gray-500");
            }
        }

        function addBubble(sender, text) {
            const div = document.createElement('div');
            const isAi = sender === "Ninad" || sender === "System";
            div.className = `flex flex-col ${isAi ? 'items-start' : 'items-end'} animate-fade-in-up`;
            
            div.innerHTML = `
                <div class="text-xs text-gray-500 mb-1">${sender}</div>
                <div class="px-4 py-2 rounded-2xl max-w-[80%] ${isAi ? 'bg-gray-800 text-blue-300 rounded-tl-none' : 'bg-blue-600 text-white rounded-tr-none'}">
                    ${text}
                </div>
            `;
            chatBox.appendChild(div);
            chatBox.scrollTop = chatBox.scrollHeight;
        }

        function logError(msg) {
            debugLog.innerText = msg;
            debugLog.style.opacity = '1';
            setTimeout(() => debugLog.style.opacity = '0', 5000);
            console.error(msg);
        }

    </script>
</body>
</html>