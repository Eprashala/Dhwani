<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dhwani - AI Teacher (Free TTS)</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* Custom styles for the app */
        body {
            font-family: 'Inter', sans-serif;
        }
        /* Style for the pulsing "listening" indicator */
        .listening-pulse {
            animation: pulse 1.5s infinite ease-in-out;
        }
        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(59, 130, 246, 0.7); }
            70% { box-shadow: 0 0 0 15px rgba(59, 130, 246, 0); }
            100% { box-shadow: 0 0 0 0 rgba(59, 130, 246, 0); }
        }
        /* Custom styles for new buttons */
        .control-btn {
            @apply px-4 py-2 rounded-lg text-sm font-medium transition-colors
                   bg-gray-600 text-white
                   hover:bg-gray-500
                   focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-offset-gray-800 focus:ring-blue-500
                   disabled:bg-gray-700 disabled:text-gray-500 disabled:cursor-not-allowed;
        }
    </style>
</head>
<body class="bg-gray-900 text-white flex items-center justify-center min-h-screen p-4">

    <div class="bg-gray-800 rounded-2xl shadow-2xl p-6 md:p-8 w-full max-w-2xl">
        
        <div class="flex items-center justify-between mb-6">
            <h1 class="text-3xl font-bold text-white">ध्वनी  AI शिक्षिका </h1>
            <div id="status-indicator" class="w-4 h-4 rounded-full bg-gray-500 transition-colors" title="Offline"></div>
        </div>

        <div id="conversation-log" class="h-80 overflow-y-auto bg-gray-900 rounded-lg p-4 mb-6 border border-gray-700 space-y-4">
            <div class="text-gray-400 text-center">Press the button and say "Dhwani" to begin.</div>
        </div>

        <div id="audio-controls" class="grid grid-cols-3 md:grid-cols-4 gap-3 mb-6">
            <button id="pause-resume-button" class="control-btn" disabled>Pause</button>
            <button id="stop-speech-button" class="control-btn" disabled>Stop</button>
            <button id="replay-button" class="control-btn" disabled>Replay</button>
            <button id="share-button" class="control-btn md:col-start-4">Share Chat</button>
        </div>

        <button id="talk-button" class="w-full py-4 px-6 rounded-lg text-lg font-semibold transition-all duration-300 ease-in-out
                       bg-blue-600 text-white
                       hover:bg-blue-700
                       focus:outline-none focus:ring-4 focus:ring-blue-500 focus:ring-opacity-50
                       disabled:bg-gray-500 disabled:cursor-not-allowed">
            Start Listening
        </button>

        </div>

    <script>
        // --- 1. DOM Elements ---
        const talkButton = document.getElementById('talk-button');
        const statusIndicator = document.getElementById('status-indicator');
        const conversationLog = document.getElementById('conversation-log');
        
        // Audio control DOM elements
        const pauseResumeButton = document.getElementById('pause-resume-button');
        const stopSpeechButton = document.getElementById('stop-speech-button');
        const replayButton = document.getElementById('replay-button');
        // NEW: Share button DOM element
        const shareButton = document.getElementById('share-button');


        // --- DANGER: API KEY ---
        // WARNING: Do NOT use this on a public website (like GitHub Pages).
        // Anyone can see this key, steal it, and use your money/quota.
        // This is ONLY for your own private, local testing.
        const GEMINI_API_KEY = "AIzaSyA4Ts-x9EKRUY9nBEegxlBUtNiJ_Qvo_zo"; 
        // -------------------------

        
        // --- 2. State Management ---
        let appState = 'IDLE'; // IDLE, LISTENING_FOR_WAKEWORD, LISTENING_FOR_NAME, LISTENING_FOR_AGE, CONVERSATION, BUSY
        let userName = '';
        let userAge = 18;
        let chatHistory = [];
        let systemInstruction = '';
        let recognition;
        let lastSpokenText = ''; // For the replay button
        let speechManuallyStopped = false; // Flag for stop button logic
        
        const synth = window.speechSynthesis;
        let voices = [];
        
        window.onload = () => {
            if (window.location.protocol !== 'https:') {
                console.warn('Note: To stop asking for mic permission, this page must be on a secure (https://) server.');
            }
        };


        // --- 3. Speech Recognition (Browser STT) ---
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        if (!SpeechRecognition) {
            logMessage('Error', 'Speech Recognition API is not supported in this browser.');
            talkButton.disabled = true;
        } else {
            recognition = new SpeechRecognition();
            recognition.continuous = false;
            recognition.interimResults = false;
            recognition.lang = 'mr-IN';

            recognition.onresult = handleSpeechResult;
            recognition.onend = handleSpeechEnd;
            recognition.onerror = (event) => {
                logMessage('Error', `Speech recognition error: ${event.error}`);
                if (appState !== 'IDLE') {
                    setState('IDLE');
                }
            };
        }

        // --- 4. Event Listeners ---
        talkButton.addEventListener('click', toggleListening);
        
        // Audio control listeners
        pauseResumeButton.addEventListener('click', togglePauseResume);
        stopSpeechButton.addEventListener('click', stopSpeech);
        replayButton.addEventListener('click', replaySpeech);
        // NEW: Share listener
        shareButton.addEventListener('click', shareChat);


        // --- 5. Core Functions ---

        function toggleListening() {
            if (GEMINI_API_KEY === "PASTE_YOUR_GEMINI_API_KEY_HERE") {
                 logMessage('Error', 'Please paste your API key into the script tag.');
                 return;
            }

            if (appState === 'IDLE') {
                setState('LISTENING_FOR_WAKEWORD');
                recognition.start();
            } else {
                setState('IDLE');
                recognition.stop();
                if (synth.speaking) {
                    synth.cancel();
                }
            }
        }

        function setState(newState) {
            appState = newState;
            console.log(`New State: ${appState}`);

            switch (newState) {
                case 'IDLE':
                    talkButton.textContent = 'Start Listening';
                    talkButton.disabled = false;
                    statusIndicator.className = 'w-4 h-4 rounded-full bg-gray-500 transition-colors';
                    statusIndicator.title = 'Offline';
                    break;
                case 'BUSY':
                    talkButton.textContent = 'Thinking...';
                    talkButton.disabled = true;
                    statusIndicator.className = 'w-4 h-4 rounded-full bg-yellow-400 transition-colors';
                    statusIndicator.title = 'Busy';
                    break;
                default: // All "LISTENING" states
                    talkButton.textContent = 'Stop Listening';
                    talkButton.disabled = false;
                    statusIndicator.className = 'w-4 h-4 rounded-full bg-blue-500 listening-pulse transition-colors';
                    statusIndicator.title = 'Listening...';
                    break;
            }
        }

        function handleSpeechEnd() {
            // Keep listening unless we are IDLE or BUSY
            if (appState !== 'IDLE' && appState !== 'BUSY') {
                try {
                    recognition.start();
                } catch (e) {
                    console.error("Safety net restart recognition error:", e);
                    setState('IDLE');
                }
            } else if (appState === 'IDLE') {
                setState('IDLE');
            }
        }
        
        async function handleSpeechResult(event) {
            const transcript = event.results[event.results.length - 1][0].transcript.trim();
            console.log(`Transcript: ${transcript}`);

            const currentState = appState;
            recognition.stop();
            setState('BUSY');

            try {
                switch (currentState) {
                    case 'LISTENING_FOR_WAKEWORD':
                        if (transcript.toLowerCase().includes('dhwani') || transcript.toLowerCase().includes('ध्वनी')) {
                            const greeting = "नमस्कार, मी ध्वनी, तुमचे नाव काय आहे?";
                            logMessage('Dhwani', greeting);
                            await speakText(greeting, 'mr-IN');
                            setState('LISTENING_FOR_NAME');
                            recognition.start(); 
                        } else {
                            setState('LISTENING_FOR_WAKEWORD');
                            recognition.start();
                        }
                        break;

                    case 'LISTENING_FOR_NAME':
                        logMessage('You', transcript);
                        userName = await extractNameFromTranscript(transcript);
                        
                        const agePrompt = `खूप छान, ${userName}, तुमचे वय काय आहे?`;
                        logMessage('Dhwani', agePrompt);
                        await speakText(agePrompt, 'mr-IN');
                        setState('LISTENING_FOR_AGE');
                        recognition.start();
                        break;

                    case 'LISTENING_FOR_AGE':
                        logMessage('You', transcript);
                        const age = await extractAgeFromTranscript(transcript);
                        userAge = Math.min(age, 18);
                        buildSystemPrompt();
                        
                        const startPrompt = `धन्यवाद, ${userName}! मी लक्षात ठेवीन की तुझे वय ${userAge} आहे. मी आता तुझ्या प्रश्नांसाठी तयार आहे!`;
                        logMessage('Dhwani', startPrompt);
                        await speakText(startPrompt, 'mr-IN');
                        setState('CONVERSATION');
                        recognition.start();
                        break;

                    case 'CONVERSATION':
                        logMessage(userName || 'You', transcript);
                        chatHistory.push({ role: 'user', parts: [{ text: transcript }] });
                        
                        const aiResponseText = await generateTextResponseFromChat();
                        const cleanedResponseText = cleanTextForTTS(aiResponseText);

                        chatHistory.push({ role: 'model', parts: [{ text: cleanedResponseText }] });
                        logMessage('Dhwani', cleanedResponseText);
                        
                        // NEW: try...catch block for speech interruption
                        try {
                            await speakText(cleanedResponseText, 'mr-IN');
                        } catch (error) {
                            if (error.message === "Speech manually stopped") {
                                console.log("Speech was stopped, auto-listen handled by stopSpeech().");
                                return; // Eject from function, stopSpeech is in control
                            }
                            throw error; // Re-throw other errors
                        }
                        
                        setState('CONVERSATION'); // Go back to listening
                        recognition.start();
                        break;
                }
            } catch (error) {
                console.error("Error in speech handling:", error);
                logMessage('Error', `Sorry, an error occurred: ${error.message}`);
                
                if (systemInstruction) {
                    setState('CONVERSATION');
                    recognition.start();
                } else {
                    setState('LISTENING_FOR_WAKEWORD');
                    recognition.start();
                }
            }
        }

        function buildSystemPrompt() {
            systemInstruction = `
                You are "Dhwani," a sweet and patient female AI teacher from Maharashtra.
                You are speaking to ${userName}, who is ${userAge} years old.
                Your task is to be a virtual teacher.
                
                RULES:
                1.  You MUST speak and answer *only* in the Marathi language using Devanagari script (मराठी फॉन्ट).
                2.  CRITICAL: Do NOT use English letters (transliteration). You MUST write "तुमचा दिवस चांगला जावो."
                3.  Do NOT include formatting in your response (like asterisks *).
                4.  You MUST tailor all answers to be easily understood by a ${userAge}-year-old.
                5.  You are kind, encouraging, and use simple language.
            `;
            // ... (rest of prompt is unchanged) ...
            
            if (userAge <= 8) {
                systemInstruction += "\n8. CRITICAL: The user is very young. Use extremely simple, short sentences. Explain things one step at a time. Be very gentle and encouraging.";
            } else if (userAge <= 12) {
                systemInstruction += "\n8. CRITICAL: The user is a child. Use simple language, but you can be a bit more detailed. Avoid complex words.";
            } else {
                systemInstruction += "\n8. CRITICAL: The user is a teenager. You can use more complex sentences, but still be encouraging and clear, like a good teacher.";
            }

            chatHistory = [{ role: 'user', parts: [{ text: 'Here are my instructions' }] }];
            chatHistory.push({ role: 'model', parts: [{ text: `Okay, I understand. I am Dhwani, a Marathi teacher, and I am speaking to ${userName} (${userAge}). I will answer all questions simply.` }] });
        }

        // --- 6. Gemini API Functions ---

        async function extractNameFromTranscript(transcript) {
            // ... (this function is unchanged) ...
            const processingMsg = document.createElement('div');
            processingMsg.innerHTML = `<strong class="text-yellow-400">Dhwani:</strong> <span class="text-gray-400">(...processing name...)</span>`;
            conversationLog.appendChild(processingMsg);
            conversationLog.scrollTop = conversationLog.scrollHeight;
            
            const apiKey = GEMINI_API_KEY;
            const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${apiKey}`;

            const extractionPrompt = `
                You are a simple utility. Your only job is to extract a single person's first name from the user's text.
                - If the user says "माझं नाव प्रमोद आहे", you respond "Pramod".
                - If the user says "प्रमोद शिंदे", you respond "Pramod".
                - If you cannot find a name, respond with "Friend".
                - Only respond with the single name. Do not add any other text.

                Text to analyze: "${transcript}"
            `;
            
            const payload = {
                contents: [{ parts: [{ text: extractionPrompt }] }],
                generationConfig: { temperature: 0.0, maxOutputTokens: 10 }
            };

            try {
                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });
                if (!response.ok) throw new Error('API Error');
                const result = await response.json();
                const name = result.candidates[0].content.parts[0].text.trim();
                conversationLog.removeChild(processingMsg);
                return name;
            } catch (error) {
                console.error("extractNameFromTranscript error:", error);
                conversationLog.removeChild(processingMsg);
                return "Friend";
            }
        }


        async function extractAgeFromTranscript(transcript) {
            // ... (this function is unchanged from last time) ...
            const processingMsg = document.createElement('div');
            processingMsg.innerHTML = `<strong class="text-yellow-400">Dhwani:</strong> <span class="text-gray-400">(...processing age...)</span>`;
            conversationLog.appendChild(processingMsg);
            conversationLog.scrollTop = conversationLog.scrollHeight;

            const apiKey = GEMINI_API_KEY;
            const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${apiKey}`;

            const extractionPrompt = `
                You are a simple utility. Your only job is to extract a single number (age) from the user's text.
                - Respond ONLY with the digits (e.g., "10", "8").
                - If you cannot find a number, respond with "18".

                EXAMPLES:
                User Text: "मी दहा वर्षांचा आहे" -> Response: "10"
                User Text: "माझं वय पंधरा आहे" -> Response: "15"
                User Text: "10 varsha" -> Response: "10"
                User Text: "majhe vaay 10 varsha aahe" -> Response: "10"
                User Text: "mi 10 varshacha aahe" -> Response: "10"
                User Text: "मी १० वर्षांचा आहे" -> Response: "10"
                User Text: "१० वर्षे" -> Response: "10"
                User Text: "माझं वय आठ आहे" -> Response: "8"

                Text to analyze: "${transcript}"
            `;

            const payload = {
                contents: [{ parts: [{ text: extractionPrompt }] }],
                generationConfig: { temperature: 0.0, maxOutputTokens: 4 }
            };

            try {
                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });
                if (!response.ok) throw new Error('API Error');
                const result = await response.json();
                const text = result.candidates[0].content.parts[0].text;
                const age = parseInt(text.trim()) || 18;
                conversationLog.removeChild(processingMsg);
                return age;
            } catch (error) {
                console.error("extractAgeFromTranscript error:", error);
                conversationLog.removeChild(processingMsg);
                return 18;
            }
        }

        async function generateTextResponseFromChat() {
            // ... (this function is unchanged) ...
            const apiKey = GEMINI_API_KEY;
            const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${apiKey}`;

            const payload = {
                contents: chatHistory,
                systemInstruction: { parts: [{ text: systemInstruction }] }
            };

            try {
                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });
                if (!response.ok) {
                    const errorBody = await response.json();
                    throw new Error(`API Error: ${response.statusText} - ${errorBody?.error?.message || 'Unknown'}`);
                }
                const result = await response.json();
                const text = result.candidates[0].content.parts[0].text.trim();
                return text;
            } catch (error) {
                console.error("Gemini Text API error:", error);
                logMessage('Error', `Failed to generate response: ${error.message}`);
                return "मला माफ करा, मला एक समस्या आली आहे.";
            }
        }
        
        function cleanTextForTTS(text) {
            return text.replace(/[\*#`]/g, ' ').replace(/\s+/g, ' ').trim();
        }

        
        // --- 7. Speech Synthesis (Browser TTS) ---

        function loadVoices() {
            voices = synth.getVoices();
            if (synth.onvoiceschanged !== undefined) {
                synth.onvoiceschanged = () => {
                    voices = synth.getVoices();
                    console.log("Voices loaded:", voices);
                };
            }
        }
        loadVoices();

        // UPDATED: Audio control functions
        
        // REQUEST 1: Pause/Replay stops the mic
        function togglePauseResume() {
            if (synth.paused) { // Clicking Resume
                synth.resume();
                pauseResumeButton.textContent = 'Pause';
                // Mic will restart automatically when speech finishes
            } else if (synth.speaking) { // Clicking Pause
                synth.pause();
                pauseResumeButton.textContent = 'Resume';
                recognition.stop(); // Stop the mic
                setState('BUSY'); // Set state to BUSY to prevent mic restart
            }
        }

        // REQUEST 2: Stop stops audio, then listens after 2s
        function stopSpeech() {
            if (!synth.speaking) return;

            speechManuallyStopped = true; // Set flag to block normal 'onend' logic
            synth.cancel(); // Stop audio
            recognition.stop(); // Stop mic

            // Manually disable buttons
            pauseResumeButton.disabled = true;
            stopSpeechButton.disabled = true;
            pauseResumeButton.textContent = 'Pause';

            logMessage('Info', 'Speech stopped. Listening in 2 seconds...');

            setTimeout(() => {
                speechManuallyStopped = false; // Reset flag
                if (systemInstruction) { 
                    setState('CONVERSATION');
                    try { recognition.start(); } catch(e) {}
                } else {
                    setState('LISTENING_FOR_WAKEWORD');
                     try { recognition.start(); } catch(e) {}
                }
            }, 2000);
        }

        // REQUEST 1: Pause/Replay stops the mic
        function replaySpeech() {
            if (lastSpokenText) {
                recognition.stop(); // Stop the mic
                setState('BUSY'); // Set state to busy
                // This will call speakText, which restarts the promise chain
                handleSpeechResult({
                    results: [[{ transcript: `(replay last message)` }]],
                    // A "fake" event to re-trigger the logic
                    // This is a bit of a hack. A cleaner way:
                    _isReplay: true 
                });
                
                // Let's do the cleaner way.
                // Re-think: Just call speakText.
                speakText(lastSpokenText);
                // The problem: `handleSpeechResult` won't know.
                // Let's stick to the simplest logic:
                // recognition.stop();
                // setState('BUSY');
                // speakText(lastSpokenText);
                // --> This will hang the `await speakText` in handleSpeechResult.
                
                // --- FINAL, ROBUST LOGIC ---
                recognition.stop(); // Stop mic
                setState('BUSY');   // Set state to busy
                // Call speakText. We don't care about the previous `await`.
                // The `onend` handler will restart listening.
                speakText(lastSpokenText); 
            }
        }
        
        // UPDATED: speakText function
        async function speakText(text, lang = 'mr-IN') {
            if (synth.speaking) {
                synth.cancel();
            }

            lastSpokenText = text;
            speechManuallyStopped = false; // Reset flag

            if (voices.length === 0) {
                voices = synth.getVoices();
            }

            return new Promise((resolve, reject) => {
                const utterance = new SpeechSynthesisUtterance(text);
                
                utterance.onstart = () => {
                    pauseResumeButton.disabled = false;
                    stopSpeechButton.disabled = false;
                    replayButton.disabled = false;
                    pauseResumeButton.textContent = 'Pause';
                };
                
                utterance.onend = () => {
                    pauseResumeButton.disabled = true;
                    stopSpeechButton.disabled = true;
                    pauseResumeButton.textContent = 'Pause';
                    
                    if (speechManuallyStopped) {
                        // REJECT the promise if stopped
                        reject(new Error("Speech manually stopped"));
                    } else {
                        // RESOLVE normally
                        resolve();
                    }
                };
                
                utterance.onerror = (event) => {
                    console.error("SpeechSynthesisUtterance.onerror", event);
                    logMessage('Error', 'Failed to play audio.');
                    pauseResumeButton.disabled = true;
                    stopSpeechButton.disabled = true;
                    reject(event.error);
                };

                // --- Find the best voice ---
                let marathiVoice = voices.find(voice => voice.lang === 'mr-IN');
                if (!marathiVoice) {
                    marathiVoice = voices.find(voice => voice.lang === 'hi-IN');
                }
                if (marathiVoice) {
                    utterance.voice = marathiVoice;
                } else {
                    utterance.lang = 'mr-IN';
                }
                
                utterance.pitch = 1;
                utterance.rate = 1;
                synth.speak(utterance);
            });
        }
        
        // --- 8. Utility Functions ---

        function logMessage(sender, message) {
            // ... (this function is unchanged) ...
            const div = document.createElement('div');
            let senderClass = 'text-blue-300 font-semibold';
            let messageClass = 'text-white';

            if (sender === 'Dhwani') {
                senderClass = 'text-cyan-300 font-semibold';
            } else if (sender === 'Error') {
                senderClass = 'text-red-400 font-bold';
                messageClass = 'text-red-300';
            } else if (sender === 'You') {
                 senderClass = 'text-green-300 font-semibold';
            } else if (sender === 'Info') {
                 senderClass = 'text-yellow-400 font-semibold';
                 messageClass = 'text-yellow-300';
            }

            div.innerHTML = `<strong class="${senderClass}">${sender}:</strong> <span class_="${messageClass}">${message}</span>`;
            conversationLog.appendChild(div);
            conversationLog.scrollTop = conversationLog.scrollHeight;
        }

        // --- 9. NEW: Share Functions ---

        /**
         * Gets the entire chat log as a clean text string.
         */
        function getChatLogAsText() {
            const messages = [];
            // Select all message divs inside the log
            conversationLog.querySelectorAll('div').forEach(div => {
                // Use textContent to get a clean "Sender: Message" string
                if (div.textContent) {
                    messages.push(div.textContent);
                }
            });
            // Join all messages with a new line
            return messages.join('\n');
        }

        /**
         * Handles the Share Chat button click.
         * Uses Web Share API (Mobile) or Clipboard API (Desktop).
         */
        async function shareChat() {
            const chatText = getChatLogAsText();
            if (!chatText || chatText.trim().length === 0) {
                logMessage('Error', 'Chat log is empty.');
                return;
            }

            const shareData = {
                title: 'Dhwani AI Teacher Chat',
                text: chatText,
            };

            // Try Web Share API (Mobile) first
            if (navigator.share) {
                try {
                    await navigator.share(shareData);
                    console.log("Chat shared successfully via Web Share");
                } catch (err) {
                    console.error("Web Share failed:", err);
                    logMessage('Error', 'Could not share chat.');
                }
            } else if (navigator.clipboard) {
                // Fallback to Clipboard API (Desktop)
                try {
                    await navigator.clipboard.writeText(chatText);
                    logMessage('Info', 'Chat copied to clipboard!');
                } catch (err) {
                    console.error("Clipboard copy failed:", err);
                    logMessage('Error', 'Could not copy chat to clipboard.');
                }
            } else {
                // No support for either
                logMessage('Error', 'Sharing and copying are not supported in this browser.');
            }
        }

    </script>
</body>
</html>