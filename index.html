<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dhwani - AI Teacher (Free TTS)</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* Custom styles for the app */
        body {
            font-family: 'Inter', sans-serif;
        }
        /* Style for the pulsing "listening" indicator */
        .listening-pulse {
            animation: pulse 1.5s infinite ease-in-out;
        }
        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(59, 130, 246, 0.7); }
            70% { box-shadow: 0 0 0 15px rgba(59, 130, 246, 0); }
            100% { box-shadow: 0 0 0 0 rgba(59, 130, 246, 0); }
        }
        /* Custom styles for new buttons */
        .control-btn {
            @apply px-4 py-2 rounded-lg text-sm font-medium transition-colors
                   bg-gray-600 text-white
                   hover:bg-gray-500
                   focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-offset-gray-800 focus:ring-blue-500
                   disabled:bg-gray-700 disabled:text-gray-500 disabled:cursor-not-allowed;
        }
    </style>
</head>
<body class="bg-gray-900 text-white flex items-center justify-center min-h-screen p-4">

    <div class="bg-gray-800 rounded-2xl shadow-2xl p-6 md:p-8 w-full max-w-2xl">
        
        <div class="flex items-center justify-between mb-6">
            <h1 class="text-3xl font-bold text-white">ध्वनी AI शिक्षिका </h1>
            <div id="status-indicator" class="w-4 h-4 rounded-full bg-gray-500 transition-colors" title="Offline"></div>
        </div>

        <div id="conversation-log" class="h-80 overflow-y-auto bg-gray-900 rounded-lg p-4 mb-6 border border-gray-700 space-y-4">
            <div class="text-gray-400 text-center">Press the button and say "Dhwani" to begin.</div>
        </div>

        <div id="audio-controls" class="flex justify-center space-x-4 mb-6">
            <button id="pause-resume-button" class="control-btn w-1/3" disabled>Pause</button>
            <button id="stop-speech-button" class="control-btn w-1/3" disabled>Stop</button>
            <button id="replay-button" class="control-btn w-1/3" disabled>Replay</button>
        </div>

        <button id="talk-button" class="w-full py-4 px-6 rounded-lg text-lg font-semibold transition-all duration-300 ease-in-out
                       bg-blue-600 text-white
                       hover:bg-blue-700
                       focus:outline-none focus:ring-4 focus:ring-blue-500 focus:ring-opacity-50
                       disabled:bg-gray-500 disabled:cursor-not-allowed">
            Start Listening
        </button>

        </div>

    <script>
        // --- 1. DOM Elements ---
        const talkButton = document.getElementById('talk-button');
        const statusIndicator = document.getElementById('status-indicator');
        const conversationLog = document.getElementById('conversation-log');
        
        // NEW: Audio control DOM elements
        const pauseResumeButton = document.getElementById('pause-resume-button');
        const stopSpeechButton = document.getElementById('stop-speech-button');
        const replayButton = document.getElementById('replay-button');


        // --- DANGER: API KEY ---
        // WARNING: Do NOT use this on a public website (like GitHub Pages).
        // Anyone can see this key, steal it, and use your money/quota.
        // This is ONLY for your own private, local testing.
        // For a public site, you MUST use the old input box method.
        const GEMINI_API_KEY = "AIzaSyA4Ts-x9EKRUY9nBEegxlBUtNiJ_Qvo_zo"; 
        // -------------------------

        
        // --- 2. State Management ---
        let appState = 'IDLE'; // IDLE, LISTENING_FOR_WAKEWORD, LISTENING_FOR_NAME, LISTENING_FOR_AGE, CONVERSATION, BUSY
        let userName = '';
        let userAge = 18;
        let chatHistory = [];
        let systemInstruction = '';
        let recognition;
        let lastSpokenText = ''; // For the replay button
        
        // --- This is the browser's built-in speech synthesizer ---
        const synth = window.speechSynthesis;
        let voices = []; // This will hold the list of available voices
        
        // --- Add window.onload to check protocol ---
        window.onload = () => {
            // Check for HTTPS (for persistent mic permission)
            if (window.location.protocol !== 'https:') {
                // We can't find 'https-warning' so let's log to console
                console.warn('Note: To stop asking for mic permission, this page must be on a secure (https://) server.');
            }
        };


        // --- 3. Speech Recognition (Browser STT) ---
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        if (!SpeechRecognition) {
            logMessage('Error', 'Speech Recognition API is not supported in this browser.');
            talkButton.disabled = true;
        } else {
            recognition = new SpeechRecognition();
            recognition.continuous = false; // We will manually control when it stops
            recognition.interimResults = false;
            recognition.lang = 'mr-IN'; // Set to Marathi

            recognition.onresult = handleSpeechResult;
            recognition.onend = handleSpeechEnd;
            recognition.onerror = (event) => {
                logMessage('Error', `Speech recognition error: ${event.error}`);
                if (appState !== 'IDLE') {
                    setState('IDLE'); // Reset on error
                }
            };
        }

        // --- 4. Event Listeners ---
        talkButton.addEventListener('click', toggleListening);
        
        // NEW: Audio control listeners
        pauseResumeButton.addEventListener('click', togglePauseResume);
        stopSpeechButton.addEventListener('click', stopSpeech);
        replayButton.addEventListener('click', replaySpeech);


        // --- 5. Core Functions ---

        function toggleListening() {
            // API key check is removed, as it's now embedded
            if (GEMINI_API_KEY === "PASTE_YOUR_GEMINI_API_KEY_HERE") {
                 logMessage('Error', 'Please paste your API key into the script tag (line 125).');
                 return;
            }

            if (appState === 'IDLE') {
                setState('LISTENING_FOR_WAKEWORD');
                recognition.start();
            } else {
                setState('IDLE');
                recognition.stop();
                if (synth.speaking) {
                    synth.cancel(); // Stop any speaking
                }
            }
        }

        function setState(newState) {
            appState = newState;
            console.log(`New State: ${appState}`); // For debugging

            switch (newState) {
                case 'IDLE':
                    talkButton.textContent = 'Start Listening';
                    talkButton.disabled = false;
                    statusIndicator.className = 'w-4 h-4 rounded-full bg-gray-500 transition-colors';
                    statusIndicator.title = 'Offline';
                    break;
                case 'BUSY':
                    talkButton.textContent = 'Thinking...';
                    talkButton.disabled = true;
                    statusIndicator.className = 'w-4 h-4 rounded-full bg-yellow-400 transition-colors';
                    statusIndicator.title = 'Busy';
                    break;
                default: // All "LISTENING" states
                    talkButton.textContent = 'Stop Listening';
                    talkButton.disabled = false;
                    statusIndicator.className = 'w-4 h-4 rounded-full bg-blue-500 listening-pulse transition-colors';
                    statusIndicator.title = 'Listening...';
                    break;
            }
        }

        function handleSpeechEnd() {
            // Keep listening unless we are IDLE or BUSY
            if (appState !== 'IDLE' && appState !== 'BUSY') {
                try {
                    // This is a safety net. If recognition stops for some reason (e.g., timeout),
                    // and we're in a listening state, restart it.
                    recognition.start();
                } catch (e) {
                    console.error("Safety net restart recognition error:", e);
                    setState('IDLE'); // Failsafe
                }
            } else if (appState === 'IDLE') {
                setState('IDLE'); // Ensure UI is reset if manually stopped
            }
        }
        
        async function handleSpeechResult(event) {
            const transcript = event.results[event.results.length - 1][0].transcript.trim();
            console.log(`Transcript: ${transcript}`);

            // --- FIX: Capture the state *before* changing it ---
            const currentState = appState;

            // Stop recognition while we process and speak
            recognition.stop();
            setState('BUSY');

            try {
                switch (currentState) { // <-- FIX: Use the captured state
                    case 'LISTENING_FOR_WAKEWORD':
                        if (transcript.toLowerCase().includes('dhwani') || transcript.toLowerCase().includes('ध्वनी')) {
                            const greeting = "नमस्कार, मी ध्वनी, तुमचे नाव काय आहे?";
                            logMessage('Dhwani', greeting);
                            await speakText(greeting, 'mr-IN');
                            setState('LISTENING_FOR_NAME');
                            recognition.start(); 
                        } else {
                            setState('LISTENING_FOR_WAKEWORD');
                            recognition.start();
                        }
                        break;

                    case 'LISTENING_FOR_NAME':
                        setState('BUSY'); 
                        logMessage('You', transcript);
                        userName = await extractNameFromTranscript(transcript);
                        
                        const agePrompt = `खूप छान, ${userName}, तुमचे वय काय आहे?`;
                        logMessage('Dhwani', agePrompt);
                        await speakText(agePrompt, 'mr-IN');
                        setState('LISTENING_FOR_AGE');
                        recognition.start();
                        break;

                    case 'LISTENING_FOR_AGE':
                        logMessage('You', transcript);
                        
                        const age = await extractAgeFromTranscript(transcript);
                        userAge = Math.min(age, 18); // Apply the "max 18" rule
                        buildSystemPrompt();
                        
                        const startPrompt = `धन्यवाद, ${userName}! मी लक्षात ठेवीन की तुझे वय ${userAge} आहे. मी आता तुझ्या प्रश्नांसाठी तयार आहे!`;
                        logMessage('Dhwani', startPrompt);
                        await speakText(startPrompt, 'mr-IN');
                        setState('CONVERSATION');
                        recognition.start();
                        break;

                    case 'CONVERSATION':
                        logMessage(userName || 'You', transcript);
                        chatHistory.push({ role: 'user', parts: [{ text: transcript }] });
                        
                        const aiResponseText = await generateTextResponseFromChat();
                        const cleanedResponseText = cleanTextForTTS(aiResponseText);

                        chatHistory.push({ role: 'model', parts: [{ text: cleanedResponseText }] });
                        logMessage('Dhwani', cleanedResponseText);
                        await speakText(cleanedResponseText, 'mr-IN');
                        
                        setState('CONVERSATION'); // Go back to listening
                        recognition.start();
                        break;
                }
            } catch (error) {
                console.error("Error in speech handling:", error);
                logMessage('Error', `Sorry, an error occurred: ${error.message}`);
                
                // Reset to a safe state and start listening again
                if (systemInstruction) {
                    setState('CONVERSATION');
                    recognition.start();
                } else {
                    setState('LISTENING_FOR_WAKEWORD');
                    recognition.start();
                }
            }
        }

        function buildSystemPrompt() {
            systemInstruction = `
                You are "Dhwani," a sweet and patient female AI teacher from Maharashtra.
                You are speaking to ${userName}, who is ${userAge} years old.
                Your task is to be a virtual teacher.
                
                RULES:
                1.  You MUST speak and answer *only* in the Marathi language using Devanagari script (मराठी फॉन्ट).
                2.  CRITICAL: Do NOT use English letters (transliteration) to write Marathi. For example, do NOT write "Tumcha divas changla javo." Instead, you MUST write "तुमचा दिवस चांगला जावो."
                3.  Do NOT include formatting in your response (like asterisks *, parentheses (), or #).
                4.  You MUST tailor all answers to be easily understood by a ${userAge}-year-old.
                5.  You are kind, encouraging, and use simple language.
                6.  Do not just give the answer; try to explain it simply, like a teacher would.
                7.  Your responses should be concise and conversational.
            `;
            
            if (userAge <= 8) {
                systemInstruction += "\n8. CRITICAL: The user is very young. Use extremely simple, short sentences. Explain things one step at a time. Be very gentle and encouraging.";
            } else if (userAge <= 12) {
                systemInstruction += "\n8. CRITICAL: The user is a child. Use simple language, but you can be a bit more detailed. Avoid complex words.";
            } else {
                systemInstruction += "\n8. CRITICAL: The user is a teenager. You can use more complex sentences, but still be encouraging and clear, like a good teacher.";
            }

            // Add the system prompt to the chat history
            chatHistory = [{ role: 'user', parts: [{ text: 'Here are my instructions' }] }];
            chatHistory.push({ role: 'model', parts: [{ text: `Okay, I understand. I am Dhwani, a Marathi teacher, and I am speaking to ${userName} (${userAge}). I will answer all questions simply.` }] });
        }

        // --- 6. Gemini API Functions ---

        async function extractNameFromTranscript(transcript) {
            const processingMsg = document.createElement('div');
            processingMsg.innerHTML = `<strong class="text-yellow-400">Dhwani:</strong> <span class="text-gray-400">(...processing name...)</span>`;
            conversationLog.appendChild(processingMsg);
            conversationLog.scrollTop = conversationLog.scrollHeight;
            
            const apiKey = GEMINI_API_KEY;
            const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${apiKey}`;

            const extractionPrompt = `
                You are a simple utility. Your only job is to extract a single person's first name from the user's text.
                - If the user says "माझं नाव प्रमोद आहे", you respond "Pramod".
                - If the user says "प्रमोद शिंदे", you respond "Pramod".
                - If the user says "मी आहे प्रमोद", you respond "Pramod".
                - If the user says "Just Pramod", you respond "Pramod".
                - If you cannot find a name, respond with "Friend".
                - Only respond with the single name. Do not add any other text.

                Text to analyze: "${transcript}"
            `;
            
            const payload = {
                contents: [{ parts: [{ text: extractionPrompt }] }],
                generationConfig: {
                    temperature: 0.0, // Be deterministic
                    maxOutputTokens: 10
                }
            };

            try {
                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });
                if (!response.ok) throw new Error('API Error');
                const result = await response.json();
                const name = result.candidates[0].content.parts[0].text.trim();
                
                conversationLog.removeChild(processingMsg); // Remove processing message
                return name;
            } catch (error) {
                console.error("extractNameFromTranscript error:", error);
                conversationLog.removeChild(processingMsg);
                return "Friend"; // Default on error
            }
        }


        async function extractAgeFromTranscript(transcript) {
            const processingMsg = document.createElement('div');
            processingMsg.innerHTML = `<strong class="text-yellow-400">Dhwani:</strong> <span class="text-gray-400">(...processing age...)</span>`;
            conversationLog.appendChild(processingMsg);
            conversationLog.scrollTop = conversationLog.scrollHeight;

            const apiKey = GEMINI_API_KEY;
            const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${apiKey}`;

            // --- IMPROVED PROMPT ---
            const extractionPrompt = `
                You are a simple utility. Your only job is to extract a single number (age) from the user's text.
                - Respond ONLY with the digits (e.g., "10", "8").
                - If you cannot find a number, respond with "18".

                EXAMPLES:
                User Text: "मी दहा वर्षांचा आहे" -> Response: "10"
                User Text: "माझं वय पंधरा आहे" -> Response: "15"
                User Text: "8" -> Response: "8"
                User Text: "My age is 40" -> Response: "40"
                User Text: "10 varsha" -> Response: "10"
                User Text: "majhe vaay 10 varsha aahe" -> Response: "10"
                User Text: "mi 10 varshacha aahe" -> Response: "10"
                User Text: "मी १० वर्षांचा आहे" (Devanagari numeral) -> Response: "10"
                User Text: "१० वर्षे" (Devanagari numeral) -> Response: "10"
                User Text: "माझं वय आठ आहे" (Marathi word) -> Response: "8"
                User Text: "Just twelve" -> Response: "12"

                Text to analyze: "${transcript}"
            `;

            const payload = {
                contents: [{ parts: [{ text: extractionPrompt }] }],
                generationConfig: {
                    temperature: 0.0,
                    maxOutputTokens: 4
                }
            };

            try {
                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });
                if (!response.ok) throw new Error('API Error');
                const result = await response.json();
                const text = result.candidates[0].content.parts[0].text;
                const age = parseInt(text.trim()) || 18; // Default to 18 if LLM fails
                
                conversationLog.removeChild(processingMsg);
                return age;
            } catch (error) {
                console.error("extractAgeFromTranscript error:", error);
                conversationLog.removeChild(processingMsg);
                return 18; // Default on error
            }
        }

        // --- This is the "Brain" function (Text Generation) ---
        async function generateTextResponseFromChat() {
            const apiKey = GEMINI_API_KEY;
            const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${apiKey}`;

            const payload = {
                contents: chatHistory,
                systemInstruction: {
                    parts: [{ text: systemInstruction }]
                }
            };

            try {
                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });
                if (!response.ok) {
                    const errorBody = await response.json();
                    throw new Error(`API Error: ${response.statusText} - ${errorBody?.error?.message || 'Unknown'}`);
                }

                const result = await response.json();
                const text = result.candidates[0].content.parts[0].text.trim();
                return text;

            } catch (error) {
                console.error("Gemini Text API error:", error);
                logMessage('Error', `Failed to generate response: ${error.message}`);
                return "मला माफ करा, मला एक समस्या आली आहे."; // Return a Marathi error
            }
        }
        
        function cleanTextForTTS(text) {
            // Removes *, #, and ` -- Parentheses are now allowed
            return text.replace(/[\*#`]/g, ' ').replace(/\s+/g, ' ').trim();
        }

        
        // --- 6. Speech Synthesis (Browser TTS) ---

        function loadVoices() {
            voices = synth.getVoices();
            if (synth.onvoiceschanged !== undefined) {
                synth.onvoiceschanged = () => {
                    voices = synth.getVoices();
                    console.log("Voices loaded:", voices);
                };
            }
        }
        loadVoices();

        // NEW: Audio control functions
        function togglePauseResume() {
            if (synth.paused) {
                synth.resume();
                pauseResumeButton.textContent = 'Pause';
            } else if (synth.speaking) {
                synth.pause();
                pauseResumeButton.textContent = 'Resume';
            }
        }

        function stopSpeech() {
            synth.cancel(); // This will trigger 'onend'
        }

        function replaySpeech() {
            if (lastSpokenText) {
                speakText(lastSpokenText);
            }
        }

        // UPDATED: speakText function
        async function speakText(text, lang = 'mr-IN') {
            if (synth.speaking) {
                synth.cancel();
            }

            // Store for replay
            lastSpokenText = text;

            if (voices.length === 0) {
                voices = synth.getVoices();
            }

            return new Promise((resolve, reject) => {
                const utterance = new SpeechSynthesisUtterance(text);
                
                // Enable buttons when speech starts
                utterance.onstart = () => {
                    pauseResumeButton.disabled = false;
                    stopSpeechButton.disabled = false;
                    replayButton.disabled = false;
                    pauseResumeButton.textContent = 'Pause';
                };
                
                // Reset buttons when speech ends
                utterance.onend = () => {
                    pauseResumeButton.disabled = true;
                    stopSpeechButton.disabled = true;
                    // replayButton remains enabled
                    pauseResumeButton.textContent = 'Pause';
                    resolve();
                };
                
                utterance.onerror = (event) => {
                    console.error("SpeechSynthesisUtterance.onerror", event);
                    logMessage('Error', 'Failed to play audio.');
                    
                    // Reset buttons on error
                    pauseResumeButton.disabled = true;
                    stopSpeechButton.disabled = true;
                    pauseResumeButton.textContent = 'Pause';
                    
                    reject(event.error);
                };

                // --- Find the best voice ---
                let marathiVoice = voices.find(voice => voice.lang === 'mr-IN');
                if (!marathiVoice) {
                    marathiVoice = voices.find(voice => voice.lang === 'hi-IN');
                }

                if (marathiVoice) {
                    utterance.voice = marathiVoice;
                    console.log("Using voice:", marathiVoice.name);
                } else {
                    utterance.lang = 'mr-IN';
                    console.warn("No 'mr-IN' or 'hi-IN' voice found. Using browser default.");
                }
                
                utterance.pitch = 1;
                utterance.rate = 1;

                synth.speak(utterance);
            });
        }
        
        // --- 7. Utility Functions ---

        function logMessage(sender, message) {
            const div = document.createElement('div');
            let senderClass = 'text-blue-300 font-semibold';
            let messageClass = 'text-white';

            if (sender === 'Dhwani') {
                senderClass = 'text-cyan-300 font-semibold';
            } else if (sender === 'Error') {
                senderClass = 'text-red-400 font-bold';
                messageClass = 'text-red-300';
            } else if (sender === 'You') {
                 senderClass = 'text-green-300 font-semibold';
            }

            div.innerHTML = `<strong class="${senderClass}">${sender}:</strong> <span class_="${messageClass}">${message}</span>`;
            conversationLog.appendChild(div);
            // Auto-scroll to the bottom
            conversationLog.scrollTop = conversationLog.scrollHeight;
        }

    </script>
</body>
</html>